# YOUTUBE DATA HARVESTING AND WAREHOUSING

## Introduction:
This YouTube Data Harvesting and Warehousing is a project that aimed at developing a user-friendly streamlit application that leverages the power of the GOOGLE API to extract valuable information from YouTube. The extracted data is then stored in a MongoDB database, subsequently migrated to a SQL data warehouse, and made accessible for analysis and exploration within the Streamlit application.

## Skills Take Away:
- Python Scripting
- Data Collection
- API Integration
- Streamlit
- Data management using MongoDB and PostgreSQL

## Installation:
 1.pip install google-api-python-client
 2.pip install pymongo
 3.pip install psycopg2
 4.pip install pandas
 5.pip install streamlit


## Process:
### Step 1 (Data collection):
The first step is to collect data from YouTube. This can be done by using YouTube Data API. The API provides a wide range of data, including channel information, video information, and viewer engagement details.

### Step 2 (Data Storage):
The second step is data storage. The collected data can be stored in multiple ways. Here we use MongoDB and PostgreSQL. Whereas MongoDB is the NoSQL database, and PostgreSQL is the relational database.

### Step 3(Data Warehousing):
The third step is Data Warehousing. The data can be stored in a data warehouse which is the centralized repository of data. Data Warehouse is used to store a large amount of data from various sources.

### Step 4 (Visualization):
The fourth step is visualization. The data can be visualized using various tools. Here we use Streamlit. Streamlit is the Python library that can be used to create an interactive web application.

## Conclusion:
This project has demonstrated how to harvest and warehouse YouTube data using PostgreSQL, MongoDB, and Streamlit. This approach can be used to collect, store, and visualize data from various sources.

---





        
