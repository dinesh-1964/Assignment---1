YOUTUBE DATA HARVESTING AND WAREHOUSING

Introduction:
•	This YouTube Data Harvesting and Warehousing is a project that aimed at developing a user-friendly streamlit application that leverages the power of the GOOGLE API to extract the valuable information from YouTube.  The extracted data is then stored in a MongoDB database, subsequently migrated to a SQL data warehouse, and made accessible for analysis and exploration within the Streamlit application.
Skills Take Away:
•	Python Scripting
•	Data Collection
•	API Integration
•	Streamlit
•	Data management using MONGO DB and POSTGRESQL
Installation:
•	Pip install google-api-python-client
•	Pip install pymongo
•	Pip install psycopg2
•	Pip install pandas
•	Pip install streamlit
Process:
	Step 1 (Data collection):
•	The first step is to collect data from You Tube. This can be done by using You Tube Data API. The API provides wide range of data, including channel information, video information and viewer engagement details.
	Step 2 (Data Storage):
•	The second step is data storage. Those collected data can be stored in multiple ways. Here we use MONGODB and POSTGRESQL. Whereas MONGODB is the NOSQL database, and POSTGRESQL is the relational database.
	Step 3(Data Warehousing):
•	The third step is Data Warehousing. Those data can be stored in a data warehouse which is the centralised repository of data. Data Warehouse is used to store a large amount of data from various sources.
	Step 4 (Visualization):
•	The fourth step is visualization. Those data can be visualize using various tools. Here we use Streamlit. Streamlit is the python library that can be used to create a interactive web application.
Conclusion:
                   This project has demonstrated how to harvest and warehouse youtube data using PostgreSQL, MongoDB and streamlit. This approach can be used to collect, store and visualize data from various sources.





        
